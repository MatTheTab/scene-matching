{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e39bfc",
   "metadata": {},
   "source": [
    "# SimCLR \n",
    "\n",
    "Notebook based (partially) on the source code from: https://github.com/The-AI-Summer/simclr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff607b4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cde562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SimCLR import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1e784",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5676c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "print(f\"Detected Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c74024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/nearest_places_mapping.csv\")\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c16fd9",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ccb36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = Augment(img_size=224)\n",
    "loader = get_data_loader(data_df, BATCH_SIZE, base_path='Eynsham/Images', transform=None, shuffle=True)\n",
    "plot_sample_batch(loader, num_examples=4, num_views=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = Augment(img_size=224)\n",
    "loader = get_data_loader(data_df, BATCH_SIZE, base_path='Eynsham/Images', transform=augmenter, shuffle=True)\n",
    "plot_sample_batch(loader, num_examples=4, num_views=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5bbae",
   "metadata": {},
   "source": [
    "## Large Embedding - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/nearest_places_mapping.csv\")\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLR_pl(EMBEDDING_SIZE_LARGE, MLP_DIM, parallel_views=True, use_adapter=False)\n",
    "available_gpus = len([torch.cuda.device(i) for i in range(torch.cuda.device_count())])\n",
    "\n",
    "transform = Augment(img_size=224)\n",
    "data_loader = get_data_loader(data_df, BATCH_SIZE, base_path='Eynsham/Images', transform=transform, shuffle=True)\n",
    "accumulator = GradientAccumulationScheduler(scheduling={0: GRADIENT_ACCUMULATION_STEPS})\n",
    "trainer = Trainer(callbacks=[accumulator],\n",
    "                  accelerator='gpu',\n",
    "                  devices=available_gpus,\n",
    "                  amp_backend=\"native\",\n",
    "                  max_epochs=MAX_EPOCHS)\n",
    "\n",
    "trainer.fit(model, data_loader)\n",
    "model = model.to(\"cpu\")\n",
    "os.makedirs(\"models/\", exist_ok=True)\n",
    "model_path = \"models/simclr_weights_large_parallel.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model weights saved to {model_path}\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a6914",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87cf3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/nearest_places_mapping.csv\")\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = data_df.head(len(data_df) - 300)\n",
    "test_df = data_df.tail(300)\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ced68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/simclr_weights_large_parallel.pth\"\n",
    "model = SimCLR_pl(EMBEDDING_SIZE_LARGE, MLP_DIM, parallel_views=True, use_adapter=False)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34290c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FineTuniningMultiViewImageDataset(train_df, base_path='Eynsham/Images', transform=None, num_views=5)\n",
    "plot_views_from_finetunedataset(dataset, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_fine_tuning(True)\n",
    "model.freeze_backbone()\n",
    "available_gpus = len([torch.cuda.device(i) for i in range(torch.cuda.device_count())])\n",
    "transform = TestAugment(img_size=224) \n",
    "train_loader = get_data_loader(train_df, BATCH_SIZE, base_path='Eynsham/Images', transform=transform, shuffle=True, fine_tune=True)\n",
    "test_loader = get_data_loader(test_df, BATCH_SIZE, base_path='Eynsham/Images', transform=transform, shuffle=True, fine_tune=True)\n",
    "\n",
    "accumulator = GradientAccumulationScheduler(scheduling={0: GRADIENT_ACCUMULATION_STEPS})\n",
    "trainer = Trainer(callbacks=[accumulator],\n",
    "                  accelerator='gpu',\n",
    "                  devices=available_gpus,\n",
    "                  max_epochs=MAX_EPOCHS)\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "model.eval()\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "os.makedirs(\"models/\", exist_ok=True)\n",
    "model_path = \"models/simclr_weights_large_parallel_fine_tuned.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model weights saved to {model_path}\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b1b5f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/simclr_weights_large_parallel_fine_tuned.pth\"\n",
    "model = SimCLR_pl(EMBEDDING_SIZE_LARGE, MLP_DIM, parallel_views=True, use_adapter=False)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83407e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TestAugment(img_size=224)\n",
    "plot_embedding_match_2d(model, test_df.copy(), base_path='Eynsham/Images', device=device, batch_size=BATCH_SIZE, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1small, top5small, top10small, distance = evaluate_embedding_accuracy(model, test_df, base_path='Eynsham/Images', transform=transform)\n",
    "print(f\"Accuracy for concatenated embeddings SimCLR: Top 1: {top1small*100:.4f}%, Top 5: {top5small*100:.4f}%, Top 10: {top10small*100:.4f}%, Mean Distance to target: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c0926",
   "metadata": {},
   "source": [
    "## Small Embedding - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111826e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/nearest_places_mapping.csv\")\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLR_pl(EMBEDDING_SIZE_SMALL, MLP_DIM, parallel_views=True, use_adapter=False)\n",
    "available_gpus = len([torch.cuda.device(i) for i in range(torch.cuda.device_count())])\n",
    "\n",
    "transform = Augment(img_size=224)\n",
    "data_loader = get_data_loader(data_df, BATCH_SIZE, base_path='Eynsham/Images', transform=transform, shuffle=True)\n",
    "accumulator = GradientAccumulationScheduler(scheduling={0: GRADIENT_ACCUMULATION_STEPS})\n",
    "trainer = Trainer(callbacks=[accumulator],\n",
    "                  accelerator='gpu',\n",
    "                  devices=available_gpus,\n",
    "                  amp_backend=\"native\",\n",
    "                  max_epochs=MAX_EPOCHS)\n",
    "\n",
    "trainer.fit(model, data_loader)\n",
    "model = model.to(\"cpu\")\n",
    "os.makedirs(\"models/\", exist_ok=True)\n",
    "model_path = \"models/simclr_weights_small_parallel.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model weights saved to {model_path}\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78c09f",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/nearest_places_mapping.csv\")\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = data_df.head(len(data_df) - 300)\n",
    "test_df = data_df.tail(300)\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a070d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/simclr_weights_small_parallel.pth\"\n",
    "model = SimCLR_pl(EMBEDDING_SIZE_SMALL, MLP_DIM, parallel_views=True, use_adapter=False)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5aba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FineTuniningMultiViewImageDataset(train_df, base_path='Eynsham/Images', transform=None, num_views=5)\n",
    "plot_views_from_finetunedataset(dataset, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e183f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_fine_tuning(True)\n",
    "model.freeze_backbone()\n",
    "available_gpus = len([torch.cuda.device(i) for i in range(torch.cuda.device_count())])\n",
    "transform = TestAugment(img_size=224) \n",
    "train_loader = get_data_loader(train_df, BATCH_SIZE, base_path='Eynsham/Images', transform=transform, shuffle=True, fine_tune=True)\n",
    "test_loader = get_data_loader(test_df, BATCH_SIZE, base_path='Eynsham/Images', transform=transform, shuffle=True, fine_tune=True)\n",
    "\n",
    "accumulator = GradientAccumulationScheduler(scheduling={0: GRADIENT_ACCUMULATION_STEPS})\n",
    "trainer = Trainer(callbacks=[accumulator],\n",
    "                  accelerator='gpu',\n",
    "                  devices=available_gpus,\n",
    "                  max_epochs=MAX_EPOCHS)\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "model.eval()\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "os.makedirs(\"models/\", exist_ok=True)\n",
    "model_path = \"models/simclr_weights_small_parallel_fine_tuned.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model weights saved to {model_path}\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738aec1e",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/simclr_weights_small_parallel_fine_tuned.pth\"\n",
    "model = SimCLR_pl(EMBEDDING_SIZE_SMALL, MLP_DIM, parallel_views=True, use_adapter=False)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TestAugment(img_size=224)\n",
    "plot_embedding_match_2d(model, test_df, base_path='Eynsham/Images', transform=transform, use_pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1small, top5small, top10small, distance = evaluate_embedding_accuracy(model, test_df, base_path='Eynsham/Images', transform=transform)\n",
    "print(f\"Accuracy for concatenated embeddings SimCLR: Top 1: {top1small*100:.4f}%, Top 5: {top5small*100:.4f}%, Top 10: {top10small*100:.4f}%, Mean Distance to target: {distance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scene_matching_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
